---
slug: HW3
title: "STudy Group 7: Homework 3"
author: "Study Group 7: Thirat Wongwaisayawan, Lejla Kajevic, Francesco Nicolì, Zitong Hu, Rufei Wang, Siddharth Gulati"
date: "2022-09-19"
output:
  html_document:
    theme: flatly
    highlight: zenburn
    number_sections: yes
    toc: yes
    toc_float: yes
    code_folding: show
---



<div id="youth-risk-behavior-surveillance" class="section level1">
<h1>Youth Risk Behavior Surveillance</h1>
<p>Every two years, the Centers for Disease Control and Prevention conduct the <a href="https://www.cdc.gov/healthyyouth/data/yrbs/index.htm">Youth Risk Behavior Surveillance System (YRBSS)</a> survey, where it takes data from high schoolers (9th through 12th grade), to analyze health patterns. You will work with a selected group of variables from a random sample of observations during one of the years the YRBSS was conducted.</p>
<div id="load-the-data" class="section level2">
<h2>Load the data</h2>
<p>This data is part of the <code>openintro</code> textbook and we can load and inspect it. There are observations on 13 different variables, some categorical and some numerical. The meaning of each variable can be found by bringing up the help file:</p>
<p>?yrbss</p>
<pre class="r"><code>data(yrbss)
glimpse(yrbss)</code></pre>
<pre><code>## Rows: 13,583
## Columns: 13
## $ age                      &lt;int&gt; 14, 14, 15, 15, 15, 15, 15, 14, 15, 15, 15, 1~
## $ gender                   &lt;chr&gt; &quot;female&quot;, &quot;female&quot;, &quot;female&quot;, &quot;female&quot;, &quot;fema~
## $ grade                    &lt;chr&gt; &quot;9&quot;, &quot;9&quot;, &quot;9&quot;, &quot;9&quot;, &quot;9&quot;, &quot;9&quot;, &quot;9&quot;, &quot;9&quot;, &quot;9&quot;, ~
## $ hispanic                 &lt;chr&gt; &quot;not&quot;, &quot;not&quot;, &quot;hispanic&quot;, &quot;not&quot;, &quot;not&quot;, &quot;not&quot;~
## $ race                     &lt;chr&gt; &quot;Black or African American&quot;, &quot;Black or Africa~
## $ height                   &lt;dbl&gt; NA, NA, 1.73, 1.60, 1.50, 1.57, 1.65, 1.88, 1~
## $ weight                   &lt;dbl&gt; NA, NA, 84.4, 55.8, 46.7, 67.1, 131.5, 71.2, ~
## $ helmet_12m               &lt;chr&gt; &quot;never&quot;, &quot;never&quot;, &quot;never&quot;, &quot;never&quot;, &quot;did not ~
## $ text_while_driving_30d   &lt;chr&gt; &quot;0&quot;, NA, &quot;30&quot;, &quot;0&quot;, &quot;did not drive&quot;, &quot;did not~
## $ physically_active_7d     &lt;int&gt; 4, 2, 7, 0, 2, 1, 4, 4, 5, 0, 0, 0, 4, 7, 7, ~
## $ hours_tv_per_school_day  &lt;chr&gt; &quot;5+&quot;, &quot;5+&quot;, &quot;5+&quot;, &quot;2&quot;, &quot;3&quot;, &quot;5+&quot;, &quot;5+&quot;, &quot;5+&quot;,~
## $ strength_training_7d     &lt;int&gt; 0, 0, 0, 0, 1, 0, 2, 0, 3, 0, 3, 0, 0, 7, 7, ~
## $ school_night_hours_sleep &lt;chr&gt; &quot;8&quot;, &quot;6&quot;, &quot;&lt;5&quot;, &quot;6&quot;, &quot;9&quot;, &quot;8&quot;, &quot;9&quot;, &quot;6&quot;, &quot;&lt;5&quot;~</code></pre>
<p>Before you carry on with your analysis, it’s is always a good idea to check with <code>skimr::skim()</code> to get a feel for missing values, summary statistics of numerical variables, and a very rough histogram.</p>
</div>
<div id="exploratory-data-analysis" class="section level2">
<h2>Exploratory Data Analysis</h2>
<pre class="r"><code> #Summarising the variable
yrbss %&gt;%
  skim(weight)</code></pre>
<table>
<caption>(#tab:eda_on_weight)Data summary</caption>
<tbody>
<tr class="odd">
<td align="left">Name</td>
<td align="left">Piped data</td>
</tr>
<tr class="even">
<td align="left">Number of rows</td>
<td align="left">13583</td>
</tr>
<tr class="odd">
<td align="left">Number of columns</td>
<td align="left">13</td>
</tr>
<tr class="even">
<td align="left">_______________________</td>
<td align="left"></td>
</tr>
<tr class="odd">
<td align="left">Column type frequency:</td>
<td align="left"></td>
</tr>
<tr class="even">
<td align="left">numeric</td>
<td align="left">1</td>
</tr>
<tr class="odd">
<td align="left">________________________</td>
<td align="left"></td>
</tr>
<tr class="even">
<td align="left">Group variables</td>
<td align="left">None</td>
</tr>
</tbody>
</table>
<p><strong>Variable type: numeric</strong></p>
<table>
<thead>
<tr class="header">
<th align="left">skim_variable</th>
<th align="right">n_missing</th>
<th align="right">complete_rate</th>
<th align="right">mean</th>
<th align="right">sd</th>
<th align="right">p0</th>
<th align="right">p25</th>
<th align="right">p50</th>
<th align="right">p75</th>
<th align="right">p100</th>
<th align="left">hist</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="left">weight</td>
<td align="right">1004</td>
<td align="right">0.93</td>
<td align="right">67.9</td>
<td align="right">16.9</td>
<td align="right">29.9</td>
<td align="right">56.2</td>
<td align="right">64.4</td>
<td align="right">76.2</td>
<td align="right">181</td>
<td align="left">▆▇▂▁▁</td>
</tr>
</tbody>
</table>
<pre class="r"><code>#Plotting the variable
ggplot(yrbss, aes(x=weight, na.rm=TRUE)) + geom_density()</code></pre>
<p><img src="/blogs/HW3_files/figure-html/eda_on_weight-1.png" width="768" style="display: block; margin: auto;" /></p>
<p>According to the summary statistics, there are 1004 missing weights data in the data set. We can also visualise the distribution of the variable “weight” and see how it is a heavily right-skewed distribution, with a most recurrent value of about 60 kg.</p>
<pre class="r"><code>correlation_summary &lt;- yrbss %&gt;% 
  group_by(physically_active_7d) %&gt;% 
  summarise(average_weight = mean(weight, na.rm = TRUE))

ggplot(correlation_summary, aes(x=physically_active_7d, y=average_weight)) + geom_col()</code></pre>
<p><img src="/blogs/HW3_files/figure-html/unnamed-chunk-2-1.png" width="768" style="display: block; margin: auto;" /></p>
<pre class="r"><code>ggplot(yrbss, aes(x=weight)) + geom_density() + facet_wrap(~physically_active_7d)</code></pre>
<p><img src="/blogs/HW3_files/figure-html/unnamed-chunk-2-2.png" width="768" style="display: block; margin: auto;" /></p>
<pre class="r"><code>#Building physical activity variable
yrbss_1 &lt;- yrbss %&gt;% 
  mutate(physical_3plus=ifelse(physically_active_7d&gt;=3,&quot;yes&quot;,&quot;no&quot;))

yrbss_1</code></pre>
<pre><code>## # A tibble: 13,583 x 14
##      age gender grade hispanic race        height weight helme~1 text_~2 physi~3
##    &lt;int&gt; &lt;chr&gt;  &lt;chr&gt; &lt;chr&gt;    &lt;chr&gt;        &lt;dbl&gt;  &lt;dbl&gt; &lt;chr&gt;   &lt;chr&gt;     &lt;int&gt;
##  1    14 female 9     not      Black or A~  NA      NA   never   0             4
##  2    14 female 9     not      Black or A~  NA      NA   never   &lt;NA&gt;          2
##  3    15 female 9     hispanic Native Haw~   1.73   84.4 never   30            7
##  4    15 female 9     not      Black or A~   1.6    55.8 never   0             0
##  5    15 female 9     not      Black or A~   1.5    46.7 did no~ did no~       2
##  6    15 female 9     not      Black or A~   1.57   67.1 did no~ did no~       1
##  7    15 female 9     not      Black or A~   1.65  132.  did no~ &lt;NA&gt;          4
##  8    14 male   9     not      Black or A~   1.88   71.2 never   &lt;NA&gt;          4
##  9    15 male   9     not      Black or A~   1.75   63.5 never   &lt;NA&gt;          5
## 10    15 male   10    not      Black or A~   1.37   97.1 did no~ &lt;NA&gt;          0
## # ... with 13,573 more rows, 4 more variables: hours_tv_per_school_day &lt;chr&gt;,
## #   strength_training_7d &lt;int&gt;, school_night_hours_sleep &lt;chr&gt;,
## #   physical_3plus &lt;chr&gt;, and abbreviated variable names 1: helmet_12m,
## #   2: text_while_driving_30d, 3: physically_active_7d</code></pre>
<pre class="r"><code>#Calculating the percentage using count()
yrbss_1 %&gt;%
  count(physical_3plus, sort=TRUE) %&gt;%
  mutate(Percentage=n/sum(n))</code></pre>
<pre><code>## # A tibble: 3 x 3
##   physical_3plus     n Percentage
##   &lt;chr&gt;          &lt;int&gt;      &lt;dbl&gt;
## 1 yes             8906     0.656 
## 2 no              4404     0.324 
## 3 &lt;NA&gt;             273     0.0201</code></pre>
<pre class="r"><code>#Calculating the percentage using group_by() and summarise()
 yrbss_1 %&gt;% 
  group_by(physical_3plus) %&gt;% 
  summarise(count=n()) %&gt;% 
  mutate(Percentage=count/sum(count))</code></pre>
<pre><code>## # A tibble: 3 x 3
##   physical_3plus count Percentage
##   &lt;chr&gt;          &lt;int&gt;      &lt;dbl&gt;
## 1 no              4404     0.324 
## 2 yes             8906     0.656 
## 3 &lt;NA&gt;             273     0.0201</code></pre>
<p>We included the “Not Available” values since those are still part of the sample but we are just not sure about the “physical activity” of those kids. Hence, excluding them would have led to deceptive proportions for both the kids exercising at least three times a week and those who exercise less.</p>
<pre class="r"><code>Proportion_formula_ci &lt;- yrbss_1 %&gt;% 
  select(physical_3plus) %&gt;%
  count(physical_3plus) %&gt;%
  summarise(Proportion=n/sum(n),
            t_critical=qt(0.975,n-1),
            se_proportion=sqrt((Proportion*(1-Proportion)/n)),
            margin_of_error=t_critical*se_proportion,
            Lower_limit=Proportion-margin_of_error,
            Upper_limit=Proportion+margin_of_error)

Proportion_formula_ci</code></pre>
<pre><code>## # A tibble: 3 x 6
##   Proportion t_critical se_proportion margin_of_error Lower_limit Upper_limit
##        &lt;dbl&gt;      &lt;dbl&gt;         &lt;dbl&gt;           &lt;dbl&gt;       &lt;dbl&gt;       &lt;dbl&gt;
## 1     0.324        1.96       0.00705         0.0138      0.310        0.338 
## 2     0.656        1.96       0.00503         0.00987     0.646        0.666 
## 3     0.0201       1.97       0.00849         0.0167      0.00338      0.0368</code></pre>
<p>Can you provide a 95% confidence interval for the population proportion of high schools that are <em>NOT</em> active 3 or more days per week?</p>
<p>Make a boxplot of <code>physical_3plus</code> vs. <code>weight</code>. Is there a relationship between these two variables? What did you expect and why?</p>
<pre class="r"><code>Mutated_yrbss &lt;- yrbss_1 %&gt;% 
  filter(physical_3plus == &quot;yes&quot;|physical_3plus==&quot;no&quot;)

#Build the plot
ggplot(Mutated_yrbss, aes(y=weight)) + geom_boxplot() + facet_wrap(~physical_3plus)</code></pre>
<p><img src="/blogs/HW3_files/figure-html/boxplot-1.png" width="648" style="display: block; margin: auto;" /></p>
<p>At a younger age, it is logical to think that more physical exercise would lead to a lower weight, since it is unlikely that a kid gains weight and muscles through physical activity. Hence, the predominant effect of exercising would a decreasing fat and, consequently, a lower weight. Given the two boxplots, though, we can see how the median weight for the kids exercising three times a week or more is actually higher than the one for those who exercise less. The two distributions are still both right-skewed but the skeweness is more pronounced for those who exercise less. This results in a higher median, even though the difference is minimal.</p>
</div>
<div id="confidence-interval" class="section level2">
<h2>Confidence Interval</h2>
<p>Boxplots show how the medians of the two distributions compare, but we can also compare the means of the distributions using either a confidence interval or a hypothesis test. Note that when we calculate the mean, SD, etc. weight in these groups using the mean function, we must ignore any missing values by setting the <code>na.rm = TRUE</code>.</p>
<pre class="r"><code>Mutated_yrbss &lt;- yrbss_1 %&gt;% 
  group_by(physical_3plus) %&gt;% 
  summarise(Average_weight=mean(weight, na.rm=TRUE),
            Standard_Deviation=sd(weight, na.rm=TRUE),
            Sample_size=n(),
            Standard_error=(Standard_Deviation/sqrt(Sample_size)),
            t_critical=qt(0.975,Sample_size-1),
            Lower_limit=(Average_weight-t_critical*Standard_error),
            Upper_limit=(Average_weight+t_critical*Standard_error)) %&gt;% 
  filter(!is.na(physical_3plus))

Mutated_yrbss</code></pre>
<pre><code>## # A tibble: 2 x 8
##   physical_3plus Average_weight Standa~1 Sampl~2 Stand~3 t_cri~4 Lower~5 Upper~6
##   &lt;chr&gt;                   &lt;dbl&gt;    &lt;dbl&gt;   &lt;int&gt;   &lt;dbl&gt;   &lt;dbl&gt;   &lt;dbl&gt;   &lt;dbl&gt;
## 1 no                       66.7     17.6    4404   0.266    1.96    66.2    67.2
## 2 yes                      68.4     16.5    8906   0.175    1.96    68.1    68.8
## # ... with abbreviated variable names 1: Standard_Deviation, 2: Sample_size,
## #   3: Standard_error, 4: t_critical, 5: Lower_limit, 6: Upper_limit</code></pre>
<p>There is an observed difference of about 1.77kg (68.44 - 66.67), and we notice that the two confidence intervals do not overlap. It seems that the difference is at least 95% statistically significant. Let us also conduct a hypothesis test.</p>
</div>
<div id="hypothesis-test-with-formula" class="section level2">
<h2>Hypothesis test with formula</h2>
<p>Write the null and alternative hypotheses for testing whether mean weights are different for those who exercise at least times a week and those who don’t.</p>
<pre class="r"><code>t.test(weight ~ physical_3plus, data = yrbss_1)</code></pre>
<pre><code>## 
##  Welch Two Sample t-test
## 
## data:  weight by physical_3plus
## t = -5, df = 7479, p-value = 9e-08
## alternative hypothesis: true difference in means between group no and group yes is not equal to 0
## 95 percent confidence interval:
##  -2.42 -1.12
## sample estimates:
##  mean in group no mean in group yes 
##              66.7              68.4</code></pre>
<p>Given that the Greek letter “delta” represents the difference between the two mean weights, we can represent the two hypotheses for the statistical test in this way:</p>
<p><span class="math inline">\(H_{0}: \delta = 0\\\)</span><span class="math inline">\(H_{1}: \delta \not= 0\)</span></p>
</div>
<div id="hypothesis-test-with-infer" class="section level2">
<h2>Hypothesis test with <code>infer</code></h2>
<p>Next, we will introduce a new function, <code>hypothesize</code>, that falls into the infer workflow. You will use this method for conducting hypothesis tests.</p>
<p>But first, we need to initialize the test, which we will save as <code>obs_diff</code>.</p>
<pre class="r"><code>obs_diff &lt;- yrbss_1 %&gt;%
  filter(!is.na(physical_3plus)) %&gt;% 
  specify(weight ~ physical_3plus) %&gt;%
  calculate(stat = &quot;diff in means&quot;, order = c(&quot;yes&quot;, &quot;no&quot;))

obs_diff</code></pre>
<pre><code>## Response: weight (numeric)
## Explanatory: physical_3plus (factor)
## # A tibble: 1 x 1
##    stat
##   &lt;dbl&gt;
## 1  1.77</code></pre>
<p>Notice how you can use the functions specify and calculate again like you did for calculating confidence intervals. Here, though, the statistic you are searching for is the difference in means, with the order being yes - no != 0.</p>
<p>After you have initialized the test, you need to simulate the test on the null distribution, which we will save as null.</p>
<pre class="r"><code>null_dist &lt;- yrbss_1 %&gt;%
  filter(!is.na(physical_3plus)) %&gt;%
  # specify variables
  specify(weight ~ physical_3plus) %&gt;%
  
  # assume independence, i.e, there is no difference
  hypothesize(null = &quot;independence&quot;) %&gt;%
  
  # generate 1000 reps, of type &quot;permute&quot;
  generate(reps = 1000, type = &quot;permute&quot;) %&gt;%
  
  # calculate statistic of difference, namely &quot;diff in means&quot;
  calculate(stat = &quot;diff in means&quot;, order = c(&quot;yes&quot;, &quot;no&quot;))

null_dist</code></pre>
<pre><code>## Response: weight (numeric)
## Explanatory: physical_3plus (factor)
## Null Hypothesis: independence
## # A tibble: 1,000 x 2
##    replicate   stat
##        &lt;int&gt;  &lt;dbl&gt;
##  1         1  0.384
##  2         2 -0.470
##  3         3 -0.651
##  4         4  0.392
##  5         5  0.304
##  6         6 -0.375
##  7         7  0.609
##  8         8 -0.263
##  9         9 -0.169
## 10        10  0.462
## # ... with 990 more rows</code></pre>
<p>Here, <code>hypothesize</code> is used to set the null hypothesis as a test for independence, i.e., that there is no difference between the two population means. In one sample cases, the null argument can be set to <em>point</em> to test a hypothesis relative to a point estimate.</p>
<p>Also, note that the <code>type</code> argument within generate is set to permute, which is the argument when generating a null distribution for a hypothesis test.</p>
<p>We can visualize this null distribution with the following code:</p>
<pre class="r"><code>ggplot(data = null_dist, aes(x = stat)) +
  geom_histogram()</code></pre>
<p><img src="/blogs/HW3_files/figure-html/unnamed-chunk-3-1.png" width="768" style="display: block; margin: auto;" /></p>
<p>Now that the test is initialized and the null distribution formed, we can visualise to see how many of these null permutations have a difference of at least <code>obs_stat</code> of 1.77?</p>
<p>We can also calculate the p-value for your hypothesis test using the function <code>infer::get_p_value()</code>.</p>
<pre class="r"><code>null_dist %&gt;% visualize() +
  shade_p_value(obs_stat = obs_diff, direction = &quot;two-sided&quot;)</code></pre>
<p><img src="/blogs/HW3_files/figure-html/unnamed-chunk-4-1.png" width="768" style="display: block; margin: auto;" /></p>
<pre class="r"><code>null_dist %&gt;%
  get_p_value(obs_stat = obs_diff, direction = &quot;two_sided&quot;)</code></pre>
<pre><code>## # A tibble: 1 x 1
##   p_value
##     &lt;dbl&gt;
## 1       0</code></pre>
<p>This the standard workflow for performing hypothesis tests.</p>
</div>
</div>
<div id="imdb-ratings-differences-between-directors" class="section level1">
<h1>IMDB ratings: Differences between directors</h1>
<p>Recall the IMBD ratings data. I would like you to explore whether the mean IMDB rating for Steven Spielberg and Tim Burton are the same or not. I have already calculated the confidence intervals for the mean ratings of these two directors and as you can see they overlap.</p>
<p>Null Hypothesis: IMDB mean rating is the same for SS and TB. difference in m =0
Alternative hypothesis: difference in mean is not equal to 0.
t-stat: difference between mean divided by standard error
p-value</p>
<pre class="r"><code>movies &lt;- read_csv(here::here(&quot;data&quot;, &quot;movies.csv&quot;))
#glimpse(movies)

movies_2 &lt;- movies %&gt;% 
  group_by(director) %&gt;% 
  filter(director %in% c(&quot;Steven Spielberg&quot;,&quot;Tim Burton&quot;)) %&gt;% 
  summarise(rating,mean_rating = mean(rating), #find datapoints needed for t distribution.
         sd_rating = sd(rating),
         count=n(),
         t_critical =qt(0.975,count-1),
         se_rating = sd(rating)/sqrt(count),
         margin_of_error = t_critical*se_rating, 
         rating_low = mean_rating - margin_of_error, 
         rating_high = mean_rating +margin_of_error,
         highest_rating =max(rating),
         lowest_rating = min(rating))

#movies_mean&lt;-count(movies, mean_rating) 
#movies_mean
movies_2</code></pre>
<pre><code>## # A tibble: 39 x 12
## # Groups:   director [2]
##    director rating mean_~1 sd_ra~2 count t_cri~3 se_ra~4 margi~5 ratin~6 ratin~7
##    &lt;chr&gt;     &lt;dbl&gt;   &lt;dbl&gt;   &lt;dbl&gt; &lt;int&gt;   &lt;dbl&gt;   &lt;dbl&gt;   &lt;dbl&gt;   &lt;dbl&gt;   &lt;dbl&gt;
##  1 Steven ~    7.9    7.57   0.695    23    2.07   0.145   0.301    7.27    7.87
##  2 Steven ~    8.1    7.57   0.695    23    2.07   0.145   0.301    7.27    7.87
##  3 Steven ~    6.2    7.57   0.695    23    2.07   0.145   0.301    7.27    7.87
##  4 Steven ~    8      7.57   0.695    23    2.07   0.145   0.301    7.27    7.87
##  5 Steven ~    8.5    7.57   0.695    23    2.07   0.145   0.301    7.27    7.87
##  6 Steven ~    6.5    7.57   0.695    23    2.07   0.145   0.301    7.27    7.87
##  7 Steven ~    6.5    7.57   0.695    23    2.07   0.145   0.301    7.27    7.87
##  8 Steven ~    8.6    7.57   0.695    23    2.07   0.145   0.301    7.27    7.87
##  9 Steven ~    8.3    7.57   0.695    23    2.07   0.145   0.301    7.27    7.87
## 10 Steven ~    7.4    7.57   0.695    23    2.07   0.145   0.301    7.27    7.87
## # ... with 29 more rows, 2 more variables: highest_rating &lt;dbl&gt;,
## #   lowest_rating &lt;dbl&gt;, and abbreviated variable names 1: mean_rating,
## #   2: sd_rating, 3: t_critical, 4: se_rating, 5: margin_of_error,
## #   6: rating_low, 7: rating_high</code></pre>
<pre class="r"><code>  ggplot(movies_2, aes(x = mean_rating,y = director))+
  geom_point() +
  geom_errorbar(data = movies_2,aes(xmin = rating_low, xmax=rating_high,height=0.2), size = 1, height = 0.1)+
  labs(x = &quot;Mean IMDB Rating&quot;,title = &quot;Do Spielburg and Burton have the same mean IMDB rating&quot;,subtitle=&quot;95% confidence interval overlap&quot;)+
    geom_rect(aes(xmin=7.27, xmax= 7.33, ymin=0, ymax=3),
            fill = &quot;grey70&quot;,
            alpha = 0.5)+
    theme_minimal()#+</code></pre>
<p><img src="/blogs/HW3_files/figure-html/load-movies-data-1.png" width="768" style="display: block; margin: auto;" /></p>
<pre class="r"><code>   # geom_text(aes(x= mean_rating, label = labels), vjust=0, nudge_y =0.05,overlap=FALSE)
  #geom_text(label=mean)
  #theme_bw()</code></pre>
<div id="analysis" class="section level2">
<h2>Analysis</h2>
<pre class="r"><code>t.test(rating~director, data = movies_2) #find t-stat, p-value</code></pre>
<pre><code>## 
##  Welch Two Sample t-test
## 
## data:  rating by director
## t = 3, df = 31, p-value = 0.01
## alternative hypothesis: true difference in means between group Steven Spielberg and group Tim Burton is not equal to 0
## 95 percent confidence interval:
##  0.16 1.13
## sample estimates:
## mean in group Steven Spielberg       mean in group Tim Burton 
##                           7.57                           6.93</code></pre>
<pre class="r"><code>#simulating a null world using infer()
set.seed(1234)
ratings_in_null_world &lt;- movies_2 %&gt;%
  specify(rating~director) %&gt;% # we want to look at ratings of directors
  hypothesize(null = &quot;independence&quot;) %&gt;%  # hypothesize that the difference is 0
  generate(reps=1000, type=&quot;permute&quot;) %&gt;% # create a bunch of simulated samples
  calculate(stat=&quot;diff in means&quot;, order = c(&quot;Steven Spielberg&quot;,&quot;Tim Burton&quot;)) # find difference in means of each sample. 

#ratings_in_null_world visualize, with shaded p value
ratings_in_null_world %&gt;% visualize() +
  shade_p_value(obs_stat = 0.64, direction = &quot;two-sided&quot;)</code></pre>
<p><img src="/blogs/HW3_files/figure-html/unnamed-chunk-5-1.png" width="768" style="display: block; margin: auto;" /></p>
<pre class="r"><code> # finding p-value of simulated distribution
p_value &lt;- ratings_in_null_world%&gt;%
  get_p_value(obs_stat = .64, direction = &quot;two-sided&quot;)
p_value</code></pre>
<pre><code>## # A tibble: 1 x 1
##   p_value
##     &lt;dbl&gt;
## 1   0.004</code></pre>
<p>With a p-value of 1%&lt;5%, we can reject the null hypothesis that Spielburg and Burton have the same mean rating.<br />
You should use both the <code>t.test</code> command and the <code>infer</code> package to simulate from a null distribution, where you assume zero difference between the two.</p>
<p>By using the infer package, we can simulate from a null distribution and compute p-values (with get_p_value()). As seen from above, the p-value from the null distribution gives 0.4%&lt;1%&lt;5%. Thus, we can infer that the null hypothesis can be rejected.</p>
<p>We can conclude that the difference in mean ratings for the two directors is unlikely to be zero.</p>
</div>
</div>
<div id="omega-group-plc--pay-discrimination" class="section level1">
<h1>Omega Group plc- Pay Discrimination</h1>
<p>At the last board meeting of Omega Group Plc., the headquarters of a large multinational company, the issue was raised that women were being discriminated in the company, in the sense that the salaries were not the same for male and female executives. A quick analysis of a sample of 50 employees (of which 24 men and 26 women) revealed that the average salary for men was about 8,700 higher than for women. This seemed like a considerable difference, so it was decided that a further analysis of the company salaries was warranted.</p>
<p>You are asked to carry out the analysis. The objective is to find out whether there is indeed a significant difference between the salaries of men and women, and whether the difference is due to discrimination or whether it is based on another, possibly valid, determining factor.</p>
<div id="loading-the-data" class="section level2">
<h2>Loading the data</h2>
<pre class="r"><code>omega &lt;- read_csv(here::here(&quot;data&quot;, &quot;omega.csv&quot;))
glimpse(omega) # examine the data frame</code></pre>
<pre><code>## Rows: 50
## Columns: 3
## $ salary     &lt;dbl&gt; 81894, 69517, 68589, 74881, 65598, 76840, 78800, 70033, 635~
## $ gender     &lt;chr&gt; &quot;male&quot;, &quot;male&quot;, &quot;male&quot;, &quot;male&quot;, &quot;male&quot;, &quot;male&quot;, &quot;male&quot;, &quot;ma~
## $ experience &lt;dbl&gt; 16, 25, 15, 33, 16, 19, 32, 34, 1, 44, 7, 14, 33, 19, 24, 3~</code></pre>
</div>
<div id="relationship-salary---gender" class="section level2">
<h2>Relationship Salary - Gender ?</h2>
<p>Calculate summary statistics on salary by gender. Also, create and print a dataframe where, for each gender, you show the mean, SD, sample size, the t-critical, the SE, the margin of error, and the low/high endpoints of a 95% condifence interval</p>
<pre class="r"><code># Summary Statistics of salary by gender
omega_2&lt;-mosaic::favstats (salary ~ gender, data=omega)
omega_2</code></pre>
<pre><code>##   gender   min    Q1 median    Q3   max  mean   sd  n missing
## 1 female 47033 60338  64618 70033 78800 64543 7567 26       0
## 2   male 54768 68331  74675 78568 84576 73239 7463 24       0</code></pre>
<pre class="r"><code># Dataframe with two rows (male-female) and having as columns gender, mean, SD, sample size,
male_female_df &lt;- omega_2 %&gt;%
  select(mean, sd,n, gender) %&gt;%
  mutate(se=sd/sqrt(n),
  t = qt(0.975,n-1),
  margin =t*se,
  l_ci =mean - margin,
  h_ci = mean +margin) %&gt;%
  select(gender, mean, sd, n, t, se, margin, l_ci, h_ci)

male_female_df</code></pre>
<pre><code>##   gender  mean   sd  n    t   se margin  l_ci  h_ci
## 1 female 64543 7567 26 2.06 1484   3056 61486 67599
## 2   male 73239 7463 24 2.07 1523   3151 70088 76390</code></pre>
<pre class="r"><code># the t-critical value, the standard error, the margin of error, 
# and the low/high endpoints of a 95% confidence interval
# The 95% confidence intervals of the two genders overlap largely, meaning that there is now a need to run t-tests to determine whether these two means are different.</code></pre>
<p>You can also run a hypothesis testing, assuming as a null hypothesis that the mean difference in salaries is zero, or that, on average, men and women make the same amount of money. You should tun your hypothesis testing using <code>t.test()</code> and with the simulation method from the <code>infer</code> package.</p>
<pre class="r"><code># hypothesis testing using t.test() 

t.test(salary~gender, data = omega) #find t-stat, p-value</code></pre>
<pre><code>## 
##  Welch Two Sample t-test
## 
## data:  salary by gender
## t = -4, df = 48, p-value = 2e-04
## alternative hypothesis: true difference in means between group female and group male is not equal to 0
## 95 percent confidence interval:
##  -12973  -4420
## sample estimates:
## mean in group female   mean in group male 
##                64543                73239</code></pre>
<pre class="r"><code>mean_dif &lt;- omega %&gt;% specify(salary~gender) %&gt;% calculate(stat = &quot;diff in means&quot;, order = c(&quot;male&quot;,&quot;female&quot;))

#simulating a null world using infer()
set.seed(1234)
ratings_in_null_world &lt;- omega %&gt;%
  specify(salary~gender) %&gt;% # we want to look at ratings of directors
  hypothesize(null = &quot;independence&quot;) %&gt;%  # hypothesize that the difference is 0
  generate(reps=1000, type=&quot;permute&quot;) %&gt;% # create a bunch of simulated samples
  calculate(stat=&quot;diff in means&quot;, order = c(&quot;male&quot;,&quot;female&quot;)) # find difference in means of each sample. 

#ratings_in_null_world visualize, with shaded p value
ratings_in_null_world %&gt;% visualize() +
  shade_p_value(obs_stat = mean_dif , direction = &quot;two-sided&quot;)</code></pre>
<p><img src="/blogs/HW3_files/figure-html/hypothesis_testing-1.png" width="768" style="display: block; margin: auto;" /></p>
<pre class="r"><code> # finding p-value of simulated distribution
p_value &lt;- ratings_in_null_world%&gt;%
  get_p_value(obs_stat = mean_dif, direction = &quot;two-sided&quot;)
p_value</code></pre>
<pre><code>## # A tibble: 1 x 1
##   p_value
##     &lt;dbl&gt;
## 1       0</code></pre>
<pre class="r"><code># hypothesis testing using infer package</code></pre>
<p>From running the simulation, we saw that the p-value is close to 0 (2e-04). This indicates that we should reject the null hypothesis and the difference in gender salary is indeed statistically different.</p>
<ul>
<li><p>We can also get the same conclusion from looking at the t-statistic. In this case, the absolute value of t-statistic is higher than 2, thus we reject the null hypothesis.</p></li>
<li><p>The third way to confirm our conclusion is to look at the confidence interval. In this case, the CI does not contain zero, thus we reject the null hypothesis.</p></li>
</ul>
</div>
<div id="relationship-experience---gender" class="section level2">
<h2>Relationship Experience - Gender?</h2>
<p>At the board meeting, someone raised the issue that there was indeed a substantial difference between male and female salaries, but that this was attributable to other reasons such as differences in experience. A questionnaire send out to the 50 executives in the sample reveals that the average experience of the men is approximately 21 years, whereas the women only have about 7 years experience on average (see table below).</p>
<pre class="r"><code># Summary Statistics of salary by gender
favstats (experience ~ gender, data=omega)</code></pre>
<pre><code>##   gender min    Q1 median   Q3 max  mean    sd  n missing
## 1 female   0  0.25    3.0 14.0  29  7.38  8.51 26       0
## 2   male   1 15.75   19.5 31.2  44 21.12 10.92 24       0</code></pre>
<pre class="r"><code>t.test(experience~gender, data = omega) #find t-stat, p-value</code></pre>
<pre><code>## 
##  Welch Two Sample t-test
## 
## data:  experience by gender
## t = -5, df = 43, p-value = 1e-05
## alternative hypothesis: true difference in means between group female and group male is not equal to 0
## 95 percent confidence interval:
##  -19.35  -8.13
## sample estimates:
## mean in group female   mean in group male 
##                 7.38                21.12</code></pre>
<pre class="r"><code>mean_dif &lt;- omega %&gt;% specify(experience~gender) %&gt;% calculate(stat = &quot;diff in means&quot;, order = c(&quot;male&quot;,&quot;female&quot;))

#simulating a null world using infer()
set.seed(1234)
ratings_in_null_world &lt;- omega %&gt;%
  specify(experience~gender) %&gt;% # we want to look at ratings of directors
  hypothesize(null = &quot;independence&quot;) %&gt;%  # hypothesize that the difference is 0
  generate(reps=1000, type=&quot;permute&quot;) %&gt;% # create a bunch of simulated samples
  calculate(stat=&quot;diff in means&quot;, order = c(&quot;male&quot;,&quot;female&quot;)) # find difference in means of each sample. 

#ratings_in_null_world visualize, with shaded p value
ratings_in_null_world %&gt;% visualize() +
  shade_p_value(obs_stat = mean_dif , direction = &quot;two-sided&quot;)</code></pre>
<p><img src="/blogs/HW3_files/figure-html/experience_stats-1.png" width="768" style="display: block; margin: auto;" /></p>
<pre class="r"><code> # finding p-value of simulated distribution
p_value &lt;- ratings_in_null_world%&gt;%
  get_p_value(obs_stat = mean_dif, direction = &quot;two-sided&quot;)
p_value</code></pre>
<pre><code>## # A tibble: 1 x 1
##   p_value
##     &lt;dbl&gt;
## 1       0</code></pre>
<p>Based on this evidence, can you conclude that there is a significant difference between the experience of the male and female executives? Perform similar analyses as in the previous section. Does your conclusion validate or endanger your conclusion about the difference in male and female salaries?</p>
<p>*Again, there are three ways to tell whether there is a statistically significant difference in the experience of male and female executives.</p>
<ul>
<li>Firstly, the confidence interval does not contain zero, thus we reject the null hypothesis and there is a significant difference in experience of the male and female executives.</li>
<li>t-statistic is larger than 2, thus we reject the null-hypothesis.</li>
<li>p-value is smaller than 5%, thus we reject the null-hypothesis.</li>
</ul>
<p>Our conclusion endangers the conclusion about the difference in male and female salaries. This is because the difference in experience is indicating that there are other factors than gender itself that can explain the difference in salary. The conclusion that there is gender discrimination in salary may be violated. Thus, further investigation is required to confirm whether other factors can also affect the difference in salaries.</p>
</div>
<div id="relationship-salary---experience" class="section level2">
<h2>Relationship Salary - Experience ?</h2>
<p>Someone at the meeting argues that clearly, a more thorough analysis of the relationship between salary and experience is required before any conclusion can be drawn about whether there is any gender-based salary discrimination in the company.</p>
<pre class="r"><code>ggplot(omega, aes(salary, experience)) + geom_point()</code></pre>
<p><img src="/blogs/HW3_files/figure-html/salary_exp_scatter-1.png" width="768" style="display: block; margin: auto;" /></p>
</div>
<div id="check-correlations-between-the-data" class="section level2">
<h2>Check correlations between the data</h2>
<pre class="r"><code>omega %&gt;% 
  select(gender, experience, salary) %&gt;% #order variables they will appear in ggpairs()
  ggpairs(aes(colour=gender, alpha = 0.3))+
  theme_bw()</code></pre>
<p><img src="/blogs/HW3_files/figure-html/ggpairs-1.png" width="768" style="display: block; margin: auto;" /></p>
<p>Salary vs Experience scatterplot: We can see that there is a positive correlation between experience and salary for both genders. The more years of work experience, the higher the salaries. The correlation coefficients (approximately 0.803 for both, 0.812 for females and 0.661 for males) calculated above confirm the observations we drew from looking at the scatterplot.</p>
<p>From the boxplots above we can also easily tell that the median work experience is much less for female executives and that female median salary is also smaller, but to a lesser extent. From the density graphs, we can see that the distribution of work experience for female is concentrated on the lower ends.</p>
<p>The above observations are suggesting that the ‘number of years worked’ is very likely to be a valid underlying factor to explain the gender salary gap. However, we cannot totally eliminate gender discrimination as a factor for gender pay gap. For instance, it is worth looking into whether there are gender related issues that prevent female executives to attain more work experience in general?</p>
<p>It would also be interesting to look at the age differences in female and male executives because that could be the underlying reason why there are significant differences in their average work experience.</p>
</div>
</div>
<div id="challenge-1-brexit-plot" class="section level1">
<h1>Challenge 1: Brexit plot</h1>
<pre class="r"><code>#load brexit data
brexit &lt;- read_csv(here::here(&quot;data&quot;, &quot;brexit_results.csv&quot;))
skim(brexit)</code></pre>
<table>
<caption><span id="tab:unnamed-chunk-6">Table 1: </span>Data summary</caption>
<tbody>
<tr class="odd">
<td align="left">Name</td>
<td align="left">brexit</td>
</tr>
<tr class="even">
<td align="left">Number of rows</td>
<td align="left">632</td>
</tr>
<tr class="odd">
<td align="left">Number of columns</td>
<td align="left">11</td>
</tr>
<tr class="even">
<td align="left">_______________________</td>
<td align="left"></td>
</tr>
<tr class="odd">
<td align="left">Column type frequency:</td>
<td align="left"></td>
</tr>
<tr class="even">
<td align="left">character</td>
<td align="left">1</td>
</tr>
<tr class="odd">
<td align="left">numeric</td>
<td align="left">10</td>
</tr>
<tr class="even">
<td align="left">________________________</td>
<td align="left"></td>
</tr>
<tr class="odd">
<td align="left">Group variables</td>
<td align="left">None</td>
</tr>
</tbody>
</table>
<p><strong>Variable type: character</strong></p>
<table>
<thead>
<tr class="header">
<th align="left">skim_variable</th>
<th align="right">n_missing</th>
<th align="right">complete_rate</th>
<th align="right">min</th>
<th align="right">max</th>
<th align="right">empty</th>
<th align="right">n_unique</th>
<th align="right">whitespace</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="left">Seat</td>
<td align="right">0</td>
<td align="right">1</td>
<td align="right">4</td>
<td align="right">43</td>
<td align="right">0</td>
<td align="right">632</td>
<td align="right">0</td>
</tr>
</tbody>
</table>
<p><strong>Variable type: numeric</strong></p>
<table>
<thead>
<tr class="header">
<th align="left">skim_variable</th>
<th align="right">n_missing</th>
<th align="right">complete_rate</th>
<th align="right">mean</th>
<th align="right">sd</th>
<th align="right">p0</th>
<th align="right">p25</th>
<th align="right">p50</th>
<th align="right">p75</th>
<th align="right">p100</th>
<th align="left">hist</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="left">con_2015</td>
<td align="right">0</td>
<td align="right">1.00</td>
<td align="right">36.60</td>
<td align="right">16.22</td>
<td align="right">0.00</td>
<td align="right">22.09</td>
<td align="right">40.85</td>
<td align="right">50.84</td>
<td align="right">65.88</td>
<td align="left">▂▅▃▇▅</td>
</tr>
<tr class="even">
<td align="left">lab_2015</td>
<td align="right">0</td>
<td align="right">1.00</td>
<td align="right">32.30</td>
<td align="right">16.54</td>
<td align="right">0.00</td>
<td align="right">17.67</td>
<td align="right">31.20</td>
<td align="right">44.37</td>
<td align="right">81.30</td>
<td align="left">▆▇▇▅▁</td>
</tr>
<tr class="odd">
<td align="left">ld_2015</td>
<td align="right">0</td>
<td align="right">1.00</td>
<td align="right">7.81</td>
<td align="right">8.36</td>
<td align="right">0.00</td>
<td align="right">2.97</td>
<td align="right">4.58</td>
<td align="right">8.57</td>
<td align="right">51.49</td>
<td align="left">▇▁▁▁▁</td>
</tr>
<tr class="even">
<td align="left">ukip_2015</td>
<td align="right">0</td>
<td align="right">1.00</td>
<td align="right">13.10</td>
<td align="right">6.47</td>
<td align="right">0.00</td>
<td align="right">9.19</td>
<td align="right">13.73</td>
<td align="right">17.11</td>
<td align="right">44.43</td>
<td align="left">▃▇▃▁▁</td>
</tr>
<tr class="odd">
<td align="left">leave_share</td>
<td align="right">0</td>
<td align="right">1.00</td>
<td align="right">52.06</td>
<td align="right">11.44</td>
<td align="right">20.48</td>
<td align="right">45.33</td>
<td align="right">53.69</td>
<td align="right">60.15</td>
<td align="right">75.65</td>
<td align="left">▂▂▆▇▂</td>
</tr>
<tr class="even">
<td align="left">born_in_uk</td>
<td align="right">0</td>
<td align="right">1.00</td>
<td align="right">88.15</td>
<td align="right">11.29</td>
<td align="right">40.73</td>
<td align="right">86.42</td>
<td align="right">92.48</td>
<td align="right">95.42</td>
<td align="right">98.02</td>
<td align="left">▁▁▁▂▇</td>
</tr>
<tr class="odd">
<td align="left">male</td>
<td align="right">0</td>
<td align="right">1.00</td>
<td align="right">49.07</td>
<td align="right">0.80</td>
<td align="right">46.86</td>
<td align="right">48.61</td>
<td align="right">49.02</td>
<td align="right">49.43</td>
<td align="right">53.05</td>
<td align="left">▁▇▃▁▁</td>
</tr>
<tr class="even">
<td align="left">unemployed</td>
<td align="right">0</td>
<td align="right">1.00</td>
<td align="right">4.37</td>
<td align="right">1.42</td>
<td align="right">1.84</td>
<td align="right">3.23</td>
<td align="right">4.19</td>
<td align="right">5.21</td>
<td align="right">9.53</td>
<td align="left">▆▇▅▂▁</td>
</tr>
<tr class="odd">
<td align="left">degree</td>
<td align="right">59</td>
<td align="right">0.91</td>
<td align="right">16.71</td>
<td align="right">8.36</td>
<td align="right">5.10</td>
<td align="right">10.79</td>
<td align="right">14.69</td>
<td align="right">19.59</td>
<td align="right">51.10</td>
<td align="left">▇▆▂▁▁</td>
</tr>
<tr class="even">
<td align="left">age_18to24</td>
<td align="right">0</td>
<td align="right">1.00</td>
<td align="right">9.29</td>
<td align="right">3.59</td>
<td align="right">5.73</td>
<td align="right">7.30</td>
<td align="right">8.28</td>
<td align="right">9.60</td>
<td align="right">32.68</td>
<td align="left">▇▁▁▁▁</td>
</tr>
</tbody>
</table>
<pre class="r"><code>#knitr::include_graphics(here::here(&quot;images&quot;, &quot;brexit.png&quot;), error = FALSE)
#transferring the data into long format instead of wide
brexit &lt;- brexit %&gt;% rename(Conservative=con_2015, Labour = lab_2015, Lib_Dems = ld_2015, UKIP = ukip_2015)

brexit2&lt;- brexit %&gt;% pivot_longer(cols=c(&#39;Conservative&#39;, &#39;Labour&#39;,&#39;Lib_Dems&#39;, &#39;UKIP&#39;),
                    names_to=&#39;parties&#39;,
                    values_to=&#39;parties_share&#39;)
#plot the data
ggplot(brexit2, aes(x =parties_share, y=leave_share, color = parties))+geom_point()+geom_smooth(method=lm)+ 
  scale_color_manual(breaks = c(&#39;Labour&#39;,&#39;Conservative&#39;, &#39;Lib_Dems&#39;, &#39;UKIP&#39;),
                        values=c(&quot;#aa1619&quot;, &quot;#3284bf&quot;,&quot;#ebbf58&quot;,&quot;#e2e039&quot;))+
  labs(x = &quot;Party % in the UK 2015 general election&quot;)+
  labs( y = &quot;Leave % in the 2016 Brexit Referendum&quot;)+
  ggtitle(&quot;How polital affiliation translated to Brexit voting&quot;)</code></pre>
<p><img src="/blogs/HW3_files/figure-html/brexit_challenge-1.png" width="768" style="display: block; margin: auto;" /></p>
</div>
<div id="challenge-2gdp-components-over-time-and-among-countries" class="section level1">
<h1>Challenge 2:GDP components over time and among countries</h1>
<p>At the risk of oversimplifying things, the main components of gross domestic product, GDP are personal consumption (C), business investment (I), government spending (G) and net exports (exports - imports). You can read more about GDP and the different approaches in calculating at the <a href="https://en.wikipedia.org/wiki/Gross_domestic_product">Wikipedia GDP page</a>.</p>
<p>The GDP data we will look at is from the <a href="https://unstats.un.org/unsd/snaama/Downloads">United Nations’ National Accounts Main Aggregates Database</a>, which contains estimates of total GDP and its components for all countries from 1970 to today. We will look at how GDP and its components have changed over time, and compare different countries and how much each component contributes to that country’s GDP. The file we will work with is <a href="http://unstats.un.org/unsd/amaapi/api/file/6">GDP and its breakdown at constant 2010 prices in US Dollars</a> and it has already been saved in the Data directory. Have a look at the Excel file to see how it is structured and organised</p>
<pre class="r"><code>UN_GDP_data  &lt;-  read_excel(here::here(&quot;data&quot;, &quot;Download-GDPconstant-USD-countries.xls&quot;), # Excel filename
                sheet=&quot;Download-GDPconstant-USD-countr&quot;, # Sheet name
                skip=2) # Number of rows to skip</code></pre>
<pre class="r"><code>tidy_GDP_data  &lt;-  UN_GDP_data%&gt;% 
  pivot_longer(cols = 4:51, names_to=&#39;years&#39;,values_to=&#39;components_GDP&#39;) %&gt;% 
  mutate(components_GDP_billions =components_GDP/(1000000000) )

glimpse(tidy_GDP_data)</code></pre>
<pre><code>## Rows: 176,880
## Columns: 6
## $ CountryID               &lt;dbl&gt; 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4~
## $ Country                 &lt;chr&gt; &quot;Afghanistan&quot;, &quot;Afghanistan&quot;, &quot;Afghanistan&quot;, &quot;~
## $ IndicatorName           &lt;chr&gt; &quot;Final consumption expenditure&quot;, &quot;Final consum~
## $ years                   &lt;chr&gt; &quot;1970&quot;, &quot;1971&quot;, &quot;1972&quot;, &quot;1973&quot;, &quot;1974&quot;, &quot;1975&quot;~
## $ components_GDP          &lt;dbl&gt; 5.56e+09, 5.33e+09, 5.20e+09, 5.75e+09, 6.15e+~
## $ components_GDP_billions &lt;dbl&gt; 5.56, 5.33, 5.20, 5.75, 6.15, 6.32, 6.37, 6.90~</code></pre>
<pre class="r"><code># Let us compare GDP components for these 3 countries
country_list &lt;- c(&quot;United States&quot;,&quot;India&quot;, &quot;Germany&quot;)</code></pre>
<div id="gdp-components-over-time" class="section level2">
<h2>GDP components over time</h2>
<pre class="r"><code>GDPdata2 &lt;- tidy_GDP_data
old_name&lt;- c(&quot;Gross capital formation&quot;,
             &quot;Exports of goods and services&quot;,
             &quot;General government final consumption expenditure&quot;, 
             &quot;Household consumption expenditure (including Non-profit institutions serving households)&quot;, 
             &quot;Imports of goods and services&quot;)


new_name&lt;- c( &quot;Gross capital formation&quot;,
              &quot;Exports&quot;,
              &quot;Government expenditure&quot;,
              &quot;Household expenditure&quot;,
              &quot;Imports&quot;)


names(new_name) &lt;-old_name
GDPdata2$IndicatorName &lt;- new_name[GDPdata2$IndicatorName]
GDPdata2 &lt;- GDPdata2 %&gt;%
  na.omit(IndicatorName)</code></pre>
<pre class="r"><code>GDP_components_over_time &lt;- GDPdata2 %&gt;% filter(Country %in% country_list) %&gt;% group_by(IndicatorName)
#GDP_components_over_time &lt;- GDP_components_over_time %&gt;% filter(IndicatorName == &#39;Household expenditure&#39;)

ggplot(GDP_components_over_time, 
       aes(x=years,y=components_GDP_billions,colour = IndicatorName))+
  geom_line(aes(group=IndicatorName))+
  facet_wrap(~Country) +
  labs(title=&quot;GDP components over time&quot;, subtitle=&quot;In constant 2010 USD&quot;) +
  theme(axis.text=element_text(size=3))+
  scale_x_discrete(breaks = c(1970,1980,1990,2000,2010,2020))+
  theme_bw()</code></pre>
<p><img src="/blogs/HW3_files/figure-html/gdp_drawing-1.png" width="768" style="display: block; margin: auto;" /></p>
<pre class="r"><code>#+theme_minimal()
#+xlim(1970,2020)</code></pre>
</div>
<div id="gdp-and-its-breakdown-at-constant-2010-prices-in-us-dollars" class="section level2">
<h2>GDP and its breakdown at constant 2010 prices in US dollars</h2>
<blockquote>
<p>What is the % difference between what you calculated as GDP and the GDP figure included in the dataframe?
The % difference between the GDP figure we calculated and that in the dataframe is 0.867%.</p>
</blockquote>
<pre class="r"><code>GDP_components_over_time2 &lt;- GDP_components_over_time %&gt;%
  select(-components_GDP) %&gt;% 
  pivot_wider(names_from=IndicatorName,
              values_from = components_GDP_billions)

colnames(GDP_components_over_time2) &lt;-c(&quot;CountryID&quot;,&quot;Country&quot;,&quot;years&quot;,&quot;Household_expenditure&quot;,&quot;Government_expenditure&quot;,&quot;Gross_capital_formation&quot;,&quot;Exports&quot;,&quot;Imports&quot;)

GDP_components_over_time3 &lt;- GDP_components_over_time2 %&gt;% 
  mutate(Net_exports=Exports-Imports,GDP_total=(Household_expenditure+Government_expenditure+Gross_capital_formation+Exports-Imports)) %&gt;%
  select(-Exports,-Imports) %&gt;%
  pivot_longer(4:7,names_to =&quot;IndicatorName&quot;,values_to=&quot;GDP_components_billions&quot;) %&gt;%
  mutate(Relative_value=GDP_components_billions/GDP_total)

ggplot(GDP_components_over_time3, 
       aes(x=years,y=Relative_value, colour=IndicatorName, group=IndicatorName)) + 
  geom_line() + 
  facet_wrap(~Country) + 
  scale_x_discrete(breaks = c(1970,1980,1990,2000,2010,2020)) + 
  scale_y_continuous(labels=scales::percent) + 
  theme_bw() + 
  labs(title = &quot;GDP and its breakdown at constant 2010 prices in US Dollars&quot;, x=&quot;years&quot;)</code></pre>
<p><img src="/blogs/HW3_files/figure-html/gdp2-1.png" width="768" style="display: block; margin: auto;" /></p>
<blockquote>
<p>What is this last chart telling you? Can you explain in a couple of paragraphs the different dynamic among these three countries?</p>
</blockquote>
<p>The last chart shows us a clear breakdown of GDP from 1970 to 2020 spread across 4 key categories - Government Expenses, Gross Capital Formation, House Expenses and Net Exports.</p>
<p>In case of House Expenditure, Germany sees a fairly constant trend over the years while the trend is extremely volatile in case of India and US. India sees a ~15pp drop in theb category while US sees a ~10pp rise. A very similar, but inverted trend is seen in case of the Gross Capital Formation.</p>
<p>Germany sees a minor drop over the years in this category while India sees a major jump, almost 20pp from 1970 to 2010 after which it drops a bit. The United States trend for the Gross Capital Formation is fairly flat at ~20% with very little variation over the years. The lowest two categories - Government Expenditure and Net Exports see mostly flat trends too. The net exports are almost 0% in all three regions - India, Germany and United States. The line for Government Expenditure is constant for Germany and India, while it sees a declining trend in case of United States.</p>
</div>
</div>
<div id="details" class="section level1">
<h1>Details</h1>
<ul>
<li>Who did you collaborate with: Lejla Kajevic, Francesco Nicolì, Zitong Hu, Rufei Wang, Siddharth Gulati</li>
</ul>
</div>
